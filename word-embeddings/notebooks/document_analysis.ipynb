{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from gensim.models import KeyedVectors, FastText\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "# import natural language toolkit\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_punctuation\n",
    "from nltk.corpus   import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.library.postgresql import PostgresQL\n",
    "from modules.library.word_models import WordModels\n",
    "from modules.library.document_similarity import DocumentSimilarity\n",
    "from modules.library.document_models import DocumentModels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the database\n",
    "\n",
    "Using the module PostgresQL we will load the documents from our database and store them in a list 'documents'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to the database\n",
    "pg = PostgresQL() \n",
    "pg.connect(database=\"eurlex_environment_only\", user=\"postgres\", password=\"dbpass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pg.execute(\"\"\"\n",
    "    SELECT * FROM documents;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddnig model\n",
    "\n",
    "In this section we will show how to use the module WordModels to load or train a word embedding model. In order to avoid runnig a time consuming commands, we will comment them out and use pickle instead to store and access already loaded or trained models. \n",
    "\n",
    "## Training a word embedding model\n",
    "\n",
    "In case we want to use pre-trained models to train another model on our data, we can use a method in module WordModels called 'train' in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"dogs like chasing cats\", \"cats like chasing mice\", \"mice eat cheese\", \"cheese has holes\", \"earth flat\", \"nobody knows working\"]\n",
    "\n",
    "sample_model = WordModels()\n",
    "sample_model.train(texts, size=300, window=1, min_count=1, epochs=10) # texts is a list of stripped strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['d', 'o', 'g', 's', ' ', 'l', 'i', 'k', 'e', 'c', 'h', 'a', 'n', 't', 'm', 'r', 'f', 'b', 'y', 'w'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model.embedding.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modules.library.word_models.WordModels"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.FastTextKeyedVectors"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample_model.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a word embedding model\n",
    "\n",
    "In case model has already been trained either by the user or has been provided from another source, module WordModels enables us to load it and use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_en_path = '../data/fasttext/wiki.en.align.vec'\n",
    "# wiki_en_model = WordModels()\n",
    "# wiki_en_model.load(wiki_en_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"wwe.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(wv_wiki_en, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"wwe.pkl\", \"rb\") as f:\n",
    "#     wiki_en_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding documents\n",
    "\n",
    "We have some documents saved in a list 'documents'. Let's embed them using DocumentModels module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_texts = [doc['document_text'] for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english') + list(string.punctuation)\n",
    "document_model = DocumentModels(wiki_en_model.embedding, document_texts, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_model.embed_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01304537, -0.00972957, -0.04939726,  0.02375953, -0.03552775],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_model.embedding[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_model.remove_documents([document_model.documents[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02488105, -0.00911847, -0.0197291 ,  0.0392039 , -0.01784342],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_model.embedding[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_model.add_documents([document_texts[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01304537, -0.00972957, -0.04939726,  0.02375953, -0.03552775],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_model.embedding[len(document_model.embedding)-1][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Similarity Analysis\n",
    "\n",
    "In order to do analysis on a corpus of documents we will use module 'DocumentSimilarity'. Below are some examples of use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DocumentSimilarity(document_model.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28714463"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.euclid_similarity(document_model.embedding[0], document_model.embedding[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_neighbors = ds.k_nearest_neighbors(document_model.embedding[0], 10, ds.euclid_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 123156, 53428, 43728, 45106, 48419, 50157, 52568, 47395, 53516]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_neighbors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
